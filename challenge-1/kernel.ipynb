{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_BASE = pathlib.Path(\"./\")\n",
    "\n",
    "PATH_DATA_RAW = PATH_BASE / \"data_raw\"\n",
    "PATH_DATA = PATH_BASE / \"data\"\n",
    "\n",
    "PATH_DATA_RAW_TRAINING = PATH_DATA_RAW / \"training\"\n",
    "PATH_DATA_RAW_OUTPUT = PATH_DATA_RAW / \"train_gt.json\"\n",
    "\n",
    "PATH_DATA_TRAINING = PATH_DATA / \"training\"\n",
    "\n",
    "PATH_DATA_TRAINING_CLASSES = [\n",
    "\tPATH_DATA_TRAINING / \"no_mask\",\n",
    "\tPATH_DATA_TRAINING / \"all_mask\",\n",
    "\tPATH_DATA_TRAINING / \"some_mask\"\n",
    "]\n",
    "\n",
    "PATH_EXPERIMENTS = PATH_BASE / \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prepares data folders\n",
    "os.makedirs(PATH_DATA_TRAINING, exist_ok=True)\n",
    "\n",
    "for p in PATH_DATA_TRAINING_CLASSES:\n",
    "\tos.makedirs(p, exist_ok=True)\n",
    "\n",
    "# loads trainings images' labels\n",
    "with open(PATH_DATA_RAW_OUTPUT) as json_file:\n",
    "    training_labels_raw = json.load(json_file)\n",
    "\n",
    "# splits the images in three list by class\n",
    "training_labels_raw = [(k, v) for k, v in training_labels_raw.items()]\n",
    "training_labels_raw = {c: list(v) for c, v in itertools.groupby(training_labels_raw, key=lambda i: i[1])}\n",
    "training_labels_raw = {k: list(map(lambda i: i[0],v)) for k, v in training_labels_raw.items()}\n",
    "\n",
    "# copy training images in the new fs struct\n",
    "for label, images in training_labels_raw.items():\n",
    "\tfor image in images:\n",
    "\t\tshutil.copy2(PATH_DATA_RAW_TRAINING / image, PATH_DATA_TRAINING_CLASSES[label])\n",
    "\t\t# on filesystem without cow support use symlink instead of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_generator_training = kr.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.3,\n",
    "    width_shift_range=10,\n",
    "    height_shift_range=10,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\",\n",
    "    rescale=1/255.,\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "dataset_generator_test = kr.preprocessing.image.ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_training = dataset_generator_training.flow_from_directory(\n",
    "    PATH_DATA_TRAINING,\n",
    "    class_mode = \"categorical\",\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    batch_size=32)\n",
    "\n",
    "dataset_validation = dataset_generator_training.flow_from_directory(\n",
    "    PATH_DATA_TRAINING,\n",
    "    class_mode = \"categorical\",\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "images, labels = dataset_training.next()\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow((images[i] * 255.).astype(\"uint8\"))\n",
    "    plt.title(list(dataset_training.class_indices.keys())[list(dataset_training.class_indices.values()).index(np.argmax(labels[i]))])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_training.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_shape=(None,*dataset_training.image_shape)\n",
    "output_shape=dataset_training.num_classes\n",
    "\n",
    "depth = 5\n",
    "start_f = 8\n",
    "\n",
    "def filters_from_depth(d:int) -> int:\n",
    "    return start_f*(2**d)\n",
    "\n",
    "model = kr.Sequential()\n",
    "\n",
    "for i in range(depth):\n",
    "\n",
    "    model.add(kr.layers.Conv2D(\n",
    "        filters=filters_from_depth(i),\n",
    "        kernel_size=(3,3),\n",
    "        strides=(1,1),\n",
    "        padding=\"same\"\n",
    "    ))\n",
    "    model.add(kr.layers.ReLU())\n",
    "    model.add(kr.layers.MaxPool2D())\n",
    "\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=512, activation=kr.activations.relu))\n",
    "#model.add(kr.layers.Dropout(0.3))\n",
    "model.add(kr.layers.Dense(units=output_shape, activation=kr.activations.softmax))\n",
    "\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=kr.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=kr.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_CURRENT_EXPERIMENT = PATH_EXPERIMENTS / datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "PATH_CHECKPOINTS = PATH_CURRENT_EXPERIMENT / \"checkpoints\"\n",
    "PATH_TENSORBOARD_LOG = PATH_CURRENT_EXPERIMENT / \"tb_log\"\n",
    "\n",
    "os.makedirs(PATH_CURRENT_EXPERIMENT, exist_ok=True)\n",
    "os.makedirs(PATH_TENSORBOARD_LOG, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    kr.callbacks.TensorBoard(PATH_TENSORBOARD_LOG,\n",
    "                             histogram_freq=1,\n",
    "                             profile_batch=0),\n",
    "    kr.callbacks.ModelCheckpoint(PATH_CHECKPOINTS),\n",
    "    kr.callbacks.EarlyStopping(patience=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    dataset_training,\n",
    "    validation_data=dataset_validation,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=dataset_training.batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#avoid this method due to https://github.com/tensorflow/tensorflow/pull/44769 still open\n",
    "\n",
    "# training_labels = list(map(lambda i: i[1], sorted(training_labels_raw.items(), key=lambda x: x[0])))\n",
    "#\n",
    "# training_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     training_image_dir,\n",
    "#     labels = training_labels,\n",
    "#     label_mode = \"categorical\",\n",
    "#     validation_split = 0.2,\n",
    "#     subset=\"training\",\n",
    "#     seed=123,\n",
    "#     image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "#     batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (challenges)",
   "language": "python",
   "name": "pycharm-882e852f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
